{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72da6c3d-b839-48cc-9376-e0cc9b2d7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "from timeit import default_timer\n",
    "from utilities3 import *\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82676edb-d4b0-4932-99df-14bd4c535fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### fourier layer ############################################\n",
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b6d232-2f20-457a-80b5-3bfd8a72c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2,  width):\n",
    "        super(FNO2d, self).__init__()\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .        \n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.fc0 = nn.Linear(3, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        size_x, size_y = x.shape[1], x.shape[2]\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = x1 + x2\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ae1f72-6edc-45a1-bb2c-61c27ee31059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FNO_main(train_data_res, save_index):\n",
    "    \"\"\"\n",
    "    train_data_res : resolution of the training data\n",
    "    save_index : index of the saving folder\n",
    "    \"\"\"    \n",
    "    #############################  configs ###################################\n",
    "    TRAIN_PATH = 'fno_tr_pre.mat'\n",
    "    #TEST_PATH = 'fno_te_pre_inter2.mat'   \n",
    "    ntrain = 5   \n",
    "    ntest = 5         \n",
    "    batch_size = 5\n",
    "    learning_rate = 0.0005    \n",
    "    epochs = 20000\n",
    "    step_size = 100\n",
    "    gamma = 0.5    \n",
    "    modes = 20\n",
    "    width = 128   \n",
    "    s = train_data_res\n",
    "    r = (101-1) // (s-1) \n",
    "    ################################################################\n",
    "    # load data and data normalization\n",
    "    ################################################################\n",
    "    reader = MatReader(TRAIN_PATH)\n",
    "    x_train = reader.read_field('coe')[:ntrain,::r,::r][:,:s,:s]\n",
    "    y_train = reader.read_field('train_y')[:ntrain,::r,::r][:,:s,:s]\n",
    "    \n",
    "#     reader.load_file(TRAIN_PATH)\n",
    "#     x_test = reader.read_field('coet')[:ntest,::r,::r][:,:s,:s]\n",
    "#     y_test = reader.read_field('train_y')[:ntest,::r,::r][:,:s,:s]\n",
    "    x_test=x_train\n",
    "    y_test=y_train\n",
    "      \n",
    "    grids = []\n",
    "    grid_all = np.linspace(0, 1, 101).reshape(101, 1).astype(np.float64)\n",
    "    grids.append(grid_all[::r,:])\n",
    "    grids.append(grid_all[::r,:])\n",
    "    grid = np.vstack([xx.ravel() for xx in np.meshgrid(*grids)]).T\n",
    "    grid = grid.reshape(1,s,s,2)\n",
    "    grid = torch.tensor(grid, dtype=torch.float)\n",
    "    x_train = torch.cat([x_train.reshape(ntrain,s,s,1), grid.repeat(ntrain,1,1,1)], dim=3)\n",
    "    x_test = torch.cat([x_test.reshape(ntest,s,s,1), grid.repeat(ntest,1,1,1)], dim=3)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    ################################################################\n",
    "    # training and evaluation\n",
    "    ################################################################\n",
    "    model = FNO2d(modes, modes, width).cuda()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    \n",
    "    start_time = default_timer()\n",
    "    myloss = LpLoss(size_average=False)\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        train_l2 = 0\n",
    "        train_mse = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            out = model(x).reshape(batch_size, s, s)\n",
    "            \n",
    "            \n",
    "            mse = F.mse_loss(out.view(batch_size, -1), y.view(batch_size, -1), reduction='mean')\n",
    "            mse.backward()\n",
    "            \n",
    "            loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n",
    "    \n",
    "            optimizer.step()\n",
    "            train_mse += mse.item()\n",
    "            train_l2 += loss.item()\n",
    "            \n",
    "        scheduler.step()\n",
    "    \n",
    "        model.eval()\n",
    "        test_l2 = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                out = model(x).reshape(batch_size, s, s)\n",
    "                test_l2 += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n",
    "                # show all figures\n",
    "                num_images=5\n",
    "                fig, axs = plt.subplots(1, num_images, figsize=(15, 5))  \n",
    "                for i in range(num_images): \n",
    "                    img = out[i].cpu().numpy()\n",
    "                    axs[i].imshow(img, cmap='jet')\n",
    "                    axs[i].set_title(f\"Image {i+1}\")\n",
    "                    axs[i].axis('off')  \n",
    "                plt.colorbar(axs[0].images[0], ax=axs, location='right')  \n",
    "                plt.show()\n",
    "\n",
    "    \n",
    "        train_mse /= len(train_loader)\n",
    "        train_l2/= ntrain\n",
    "        test_l2 /= ntest\n",
    "    \n",
    "        t2 = default_timer()\n",
    "        print(\"Epoch: %d, time: %.3f, Train Loss: %.3e, Train l2: %.4f, Test l2: %.4f\" \n",
    "                  % ( ep, t2-t1, train_mse, train_l2, test_l2) )\n",
    "\n",
    "    elapsed = default_timer() - start_time\n",
    "   \n",
    "    # ====================================\n",
    "    # saving settings\n",
    "    # ====================================\n",
    "    current_directory = os.getcwd()\n",
    "    resolution = \"TrainRes_\"+str(train_data_res)\n",
    "    folder_index = str(save_index)\n",
    "    \n",
    "    results_dir = \"/results/\" + resolution +\"/\" + folder_index +\"/\"\n",
    "    save_results_to = current_directory + results_dir\n",
    "    if not os.path.exists(save_results_to):\n",
    "        os.makedirs(save_results_to)\n",
    "        \n",
    "    model_dir = \"/model/\" + resolution +\"/\" + folder_index +\"/\"\n",
    "    save_models_to = current_directory + model_dir\n",
    "    if not os.path.exists(save_models_to):\n",
    "        os.makedirs(save_models_to)\n",
    "        \n",
    "    ################################################################\n",
    "    # testing\n",
    "    ################################################################\n",
    "    torch.save(model, save_models_to+'fourier_burger')\n",
    "    \n",
    "    test_data_res = train_data_res\n",
    "    s = test_data_res\n",
    "    r = (101-1) // (s-1) \n",
    "    \n",
    "    reader.load_file(TEST_PATH)\n",
    "    x_test = reader.read_field('coet2')[:ntest,::r,::r][:,:s,:s]\n",
    "    y_test = reader.read_field('test_yinter')[:ntest,::r,::r][:,:s,:s]\n",
    "    \n",
    "    grids = []\n",
    "    grids.append(grid_all[::r,:])\n",
    "    grids.append(grid_all[::r,:])\n",
    "    grid = np.vstack([xx.ravel() for xx in np.meshgrid(*grids)]).T\n",
    "    grid = grid.reshape(1,s,s,2)\n",
    "    grid = torch.tensor(grid, dtype=torch.float)\n",
    "    x_test = torch.cat([x_test.reshape(ntest,s,s,1), grid.repeat(ntest,1,1,1)], dim=3)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=1, shuffle=False)\n",
    "    \n",
    "    pred = torch.zeros(y_test.shape)\n",
    "    index = 0\n",
    "    t1 = default_timer()\n",
    "    test_l2 = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            out = model(x).reshape(1, s, s)\n",
    "            \n",
    "            pred[index:index+1,:,:] = out\n",
    "    \n",
    "            test_l2 += np.linalg.norm(out.view(1, -1).cpu().numpy() \n",
    "                                      - y.view(1, -1).cpu().numpy()) / np.linalg.norm(y.view(1, -1).cpu().numpy())\n",
    "            index = index + 1\n",
    "    t2 = default_timer()\n",
    "    testing_time = t2-t1\n",
    "     \n",
    "    test_l2 = test_l2/index    \n",
    "    \n",
    "    scipy.io.savemat(save_results_to+'burger_test_inter_'+str(test_data_res)+'.mat', \n",
    "                        mdict={'x_test': reader.read_field('coet2')[:ntest,::r,::r][:,:s,:s].numpy(),\n",
    "                               'y_test': y_test.numpy(), \n",
    "                               'y_pred': pred.cpu().numpy(),\n",
    "                               'testing_time': testing_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb5540d-1ed4-4412-9336-669bb6e4b333",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FNO_main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m training_data_resolution \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m101\u001b[39m\n\u001b[0;32m      4\u001b[0m run_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 5\u001b[0m FNO_main(training_data_resolution, run_index)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FNO_main' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    training_data_resolution = 101\n",
    "    run_index = 0\n",
    "    FNO_main(training_data_resolution, run_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c96ac418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DV Group\\AppData\\Local\\Temp\\ipykernel_54264\\2050771345.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('D:/Liang/PIDON_NIF_20241202/FNO\\model/TrainRes_101/0/fourier_darcy_20000nonorm')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "train_data_res=101\n",
    "ntrain = 5   \n",
    "ntest = 1        \n",
    "batch_size = 1\n",
    "learning_rate = 0.001    \n",
    "epochs = 2000\n",
    "step_size = 100\n",
    "gamma = 0.5    \n",
    "modes = 12\n",
    "width = 32   \n",
    "s = train_data_res\n",
    "r = (101-1) // (s-1) \n",
    "TRAIN_PATH = 'fno_tr_pre.mat'\n",
    "TEST_PATH = 'fno_te_pre_inter.mat' \n",
    "reader = MatReader(TEST_PATH)\n",
    "reader.load_file(TEST_PATH)\n",
    "test_data_res=101\n",
    "################################################################\n",
    "# testing\n",
    "################################################################\n",
    "model = torch.load('D:/Liang/FNO/model/fourier_burger')\n",
    "\n",
    "test_data_res = train_data_res\n",
    "s = test_data_res\n",
    "r = (101-1) // (s-1) \n",
    "\n",
    "reader.load_file(TEST_PATH)\n",
    "x_test = reader.read_field('coet2')[:ntest,::r,::r][:,:s,:s]\n",
    "y_test = reader.read_field('test_yinter')[:ntest,::r,::r][:,:s,:s]\n",
    "\n",
    "grids = []\n",
    "grid_all = np.linspace(0, 1, 101).reshape(101, 1).astype(np.float64)\n",
    "grid_all_3 = np.linspace(0,1,101).reshape(101, 1).astype(np.float64)\n",
    "grids.append(grid_all_3[::r,:])\n",
    "grids.append(grid_all[::r,:])\n",
    "grid = np.vstack([xx.ravel() for xx in np.meshgrid(*grids)]).T\n",
    "grid = grid.reshape(1,s,s,2)\n",
    "grid = torch.tensor(grid, dtype=torch.float)\n",
    "x_test = torch.cat([x_test.reshape(ntest,s,s,1), grid.repeat(ntest,1,1,1)], dim=3)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=1, shuffle=False)\n",
    "\n",
    "pred = torch.zeros(y_test.shape)\n",
    "index = 0\n",
    "t1 = default_timer()\n",
    "test_l2 = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        out = model(x).reshape(1, s, s)\n",
    "        pred[index:index+1,:,:] = out\n",
    "\n",
    "        test_l2 += np.linalg.norm(out.view(1, -1).cpu().numpy() \n",
    "                                  - y.view(1, -1).cpu().numpy()) / np.linalg.norm(y.view(1, -1).cpu().numpy())\n",
    "        index = index + 1\n",
    "t2 = default_timer()\n",
    "testing_time = t2-t1\n",
    "print('testing time: ', testing_time)\n",
    "test_l2 = test_l2/index\n",
    "# ====================================\n",
    "current_directory = os.getcwd()\n",
    "resolution = \"TrainRes_\"+str(train_data_res)\n",
    "save_index=0\n",
    "folder_index = str(save_index)\n",
    "\n",
    "results_dir = \"/results/\" + resolution +\"/\" + folder_index +\"/\"\n",
    "save_results_to = current_directory + results_dir\n",
    "\n",
    "scipy.io.savemat(save_results_to+'burger_test_inter_'+str(test_data_res)+'.mat', \n",
    "                    mdict={'x_test': reader.read_field('coet2')[:ntest,::r,::r][:,:s,:s].numpy(),\n",
    "                           'y_test': y_test.numpy(), \n",
    "                           'y_pred': pred.cpu().numpy(),\n",
    "                           'testing_time': testing_time})\n",
    "\n",
    "print('finished')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL_nif)",
   "language": "python",
   "name": "dl_nif"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
